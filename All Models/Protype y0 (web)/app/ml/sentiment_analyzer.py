
# -*- coding: utf-8 -*-
"""
ÙˆØ­Ø¯Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
"""
import re
import json
import os
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
import joblib

# Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ©
ARABIC_POSITIVE_WORDS = [
    "Ø¬Ù…ÙŠÙ„", "Ø±Ø§Ø¦Ø¹", "Ù…Ù…ØªØ§Ø²", "Ø¬ÙŠØ¯", "Ø¹Ø¸ÙŠÙ…", "Ù…Ø­ØªØ±Ù…", "Ù…Ø°Ù‡Ù„", "Ø³Ø¹ÙŠØ¯", "ÙØ±Ø­",
    "Ù…Ø¨Ù‡Ø¬", "Ù†Ø§Ø¬Ø­", "Ù…ÙˆÙÙ‚", "Ù…ØªÙÙˆÙ‚", "Ù…Ø¨Ø¯Ø¹", "Ù…Ø«Ø§Ù„ÙŠ", "Ù…ÙÙŠØ¯", "Ù…Ù…ØªØ¹", "Ù…Ø­Ø¨ÙˆØ¨",
    "ÙˆØ¯ÙˆØ¯", "Ù„Ø·ÙŠÙ", "ÙƒØ±ÙŠÙ…", "Ù…Ø³Ø§Ø¹Ø¯", "Ù…ØªØ¹Ø§ÙˆÙ†", "Ù…Ø®Ù„Øµ", "ØµØ§Ø¯Ù‚", "Ø£Ù…ÙŠÙ†", "ÙˆÙÙŠ"
]

ARABIC_NEGATIVE_WORDS = [
    "Ø³ÙŠØ¡", "Ø±Ø¯ÙŠØ¡", "Ù‚Ø¨ÙŠØ­", "Ø³Ø®ÙŠÙ", "ØªØ§ÙÙ‡", "Ù…Ø²Ø¹Ø¬", "Ù…Ù‚Ø±Ù", "Ø¨Ø´Ø¹", "Ù…Ø®ÙŠÙ",
    "Ù…Ø±Ø¹Ø¨", "ÙØ§Ø´Ù„", "Ù…Ø­Ø¨Ø·", "Ù…Ø¤Ù„Ù…", "Ù…ØªØ¹Ø¨", "ØµØ¹Ø¨", "Ù…Ø¹Ù‚Ø¯", "ØºØ§Ø¶Ø¨", "Ø­Ø²ÙŠÙ†",
    "Ù…ÙƒØªØ¦Ø¨", "Ø®Ø§Ø¦Ù", "Ù…ØªÙˆØªØ±", "Ù‚Ù„Ù‚", "Ù…Ø±Ù‡Ù‚", "Ù…Ø±ÙŠØ¶", "Ù…Ø¤Ø°ÙŠ", "ÙƒØ§Ø°Ø¨", "Ø®Ø§Ø¦Ù†"
]

ENGLISH_POSITIVE_WORDS = [
    "good", "great", "excellent", "amazing", "wonderful", "fantastic", "brilliant",
    "happy", "joyful", "pleased", "satisfied", "delighted", "successful", "perfect",
    "beautiful", "lovely", "helpful", "useful", "interesting", "outstanding", "awesome"
]

ENGLISH_NEGATIVE_WORDS = [
    "bad", "terrible", "awful", "horrible", "disappointing", "poor", "sad", "angry",
    "upset", "annoying", "irritating", "depressing", "frustrating", "boring", "disgusting",
    "ugly", "useless", "stupid", "difficult", "painful", "failure", "hate", "worst"
]

class SentimentAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©"""
    
    def __init__(self, language="both"):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ"""
        self.language = language
        self.model_path = {
            "ar": "models/arabic_sentiment_model.pkl",
            "en": "models/english_sentiment_model.pkl"
        }
        self.vectorizers = {}
        self.models = {}
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
        self._load_models()
    
    def _load_models(self):
        """Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹"""
        for lang in ["ar", "en"]:
            try:
                model = joblib.load(self.model_path[lang])
                self.models[lang] = model
                print(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ {lang} Ø¨Ù†Ø¬Ø§Ø­")
            except:
                print(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ {lang}ØŒ Ø³ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ")
                # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
                self._create_default_model(lang)
    
    def _create_default_model(self, lang):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‚ÙˆØ§Ù…ÙŠØ³ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…ØµØ¯Ø± Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø³ÙŠØ·
        if lang == "ar":
            pos_words = ARABIC_POSITIVE_WORDS
            neg_words = ARABIC_NEGATIVE_WORDS
        else:  # en
            pos_words = ENGLISH_POSITIVE_WORDS
            neg_words = ENGLISH_NEGATIVE_WORDS
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù…Ù„ Ø¨Ø³ÙŠØ·Ø© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
        training_data = []
        labels = []
        
        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
        for word in pos_words:
            training_data.append(f"Ù‡Ø°Ø§ {word}")
            labels.append(1)
            training_data.append(f"{word} Ø¬Ø¯Ø§Ù‹")
            labels.append(1)
        
        # Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù„Ø¨ÙŠØ©
        for word in neg_words:
            training_data.append(f"Ù‡Ø°Ø§ {word}")
            labels.append(0)
            training_data.append(f"{word} Ø¬Ø¯Ø§Ù‹")
            labels.append(0)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(training_data)
        model = LogisticRegression()
        model.fit(X, labels)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
        self.vectorizers[lang] = vectorizer
        self.models[lang] = model
    
    def _detect_language(self, text):
        """ØªØ­Ø¯ÙŠØ¯ Ù„ØºØ© Ø§Ù„Ù†Øµ"""
        arabic_pattern = re.compile(r'[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF]+')
        if arabic_pattern.search(text):
            return "ar"
        return "en"  # Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù‡Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
    
    def analyze_text(self, text):
        """ØªØ­Ù„ÙŠÙ„ Ø¹Ø§Ø·ÙØ© Ø§Ù„Ù†Øµ"""
        if not text or not isinstance(text, str):
            return {"sentiment": "neutral", "score": 0.5, "confidence": 0}
        
        # ØªØ­Ø¯ÙŠØ¯ Ù„ØºØ© Ø§Ù„Ù†Øµ
        lang = self._detect_language(text)
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ (Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø©)
        if lang == "ar":
            pos_dict = ARABIC_POSITIVE_WORDS
            neg_dict = ARABIC_NEGATIVE_WORDS
        else:  # en
            pos_dict = ENGLISH_POSITIVE_WORDS
            neg_dict = ENGLISH_NEGATIVE_WORDS
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
        text = text.lower()
        
        # Ø¹Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ÙˆØ§Ù„Ø³Ù„Ø¨ÙŠØ©
        positive_count = sum(1 for word in pos_dict if word in text)
        negative_count = sum(1 for word in neg_dict if word in text)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø©
        total = positive_count + negative_count
        if total == 0:
            sentiment = "neutral"
            score = 0.5
            confidence = 0
        else:
            score = positive_count / total
            if score > 0.6:
                sentiment = "positive"
            elif score < 0.4:
                sentiment = "negative"
            else:
                sentiment = "neutral"
            confidence = abs(score - 0.5) * 2  # 0 to 1
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
        if lang in self.models and self.vectorizers.get(lang):
            try:
                X = self.vectorizers[lang].transform([text])
                model_score = self.models[lang].predict_proba(X)[0][1]  # Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©
                
                # Ø¯Ù…Ø¬ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
                score = (score + model_score) / 2
                if score > 0.6:
                    sentiment = "positive"
                elif score < 0.4:
                    sentiment = "negative"
                else:
                    sentiment = "neutral"
                confidence = abs(score - 0.5) * 2
            except:
                # Ø§Ø³ØªÙ…Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø­Ø³ÙˆØ¨Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
                pass
        
        return {
            "sentiment": sentiment,
            "score": score,
            "confidence": confidence,
            "language": lang,
            "positive_words": positive_count,
            "negative_words": negative_count
        }
    
    def train_model(self, texts, labels, language=None):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø¬Ø¯ÙŠØ¯ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ÙŠÙ†Ø©"""
        if language is None:
            language = self._detect_language(texts[0]) if texts else "en"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(texts)
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_train, X_test, y_train, y_test = train_test_split(
            X, labels, test_size=0.2, random_state=42
        )
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = LogisticRegression()
        model.fit(X_train, y_train)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        accuracy = model.score(X_test, y_test)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        self.vectorizers[language] = vectorizer
        self.models[language] = model
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
        os.makedirs(os.path.dirname(self.model_path[language]), exist_ok=True)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ù…Ù„Ù
        model_pipeline = Pipeline([
            ('vectorizer', vectorizer),
            ('classifier', model)
        ])
        joblib.dump(model_pipeline, self.model_path[language])
        
        return {
            "accuracy": accuracy,
            "language": language,
            "model_path": self.model_path[language]
        }
    
    @staticmethod
    def get_emotion_emoji(sentiment):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ù…Ø² ØªØ¹Ø¨ÙŠØ±ÙŠ Ù„Ù„Ù…Ø´Ø§Ø¹Ø±"""
        if sentiment == "positive":
            return "ðŸ˜ƒ"
        elif sentiment == "negative":
            return "ðŸ˜”"
        else:
            return "ðŸ˜"

# ÙˆØ¸ÙŠÙØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
def analyze_sentiment(text):
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±"""
    analyzer = SentimentAnalyzer()
    result = analyzer.analyze_text(text)
    return result
